<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>林伟源的技术博客</title>
  
  
  <link href="https://linweiyuan.github.io/atom.xml" rel="self"/>
  
  <link href="https://linweiyuan.github.io/"/>
  <updated>2024-07-24T01:14:42.857Z</updated>
  <id>https://linweiyuan.github.io/</id>
  
  <author>
    <name>林伟源</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>参加一个 Rust 活动</title>
    <link href="https://linweiyuan.github.io/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8.html"/>
    <id>https://linweiyuan.github.io/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8.html</id>
    <published>2024-07-20T12:54:42.000Z</published>
    <updated>2024-07-24T01:14:42.857Z</updated>
    
    <content type="html"><![CDATA[<p>今天也是来见见世面</p><p>有大学生，有前后端、嵌入式、Web3、自媒体，有大厂技术人员，收获还是挺多的</p><p>也和多年不见的同学见了面</p><p><img src="/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8/1.jpg"></p><p><img src="/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8/2.jpg"></p><p><img src="/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8/3.jpg"></p><p><img src="/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8/4.jpg"></p><p><img src="/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B8%AA-Rust-%E6%B4%BB%E5%8A%A8/5.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天也是来见见世面&lt;/p&gt;
&lt;p&gt;有大学生，有前后端、嵌入式、Web3、自媒体，有大厂技术人员，收获还是挺多的&lt;/p&gt;
&lt;p&gt;也和多年不见的同学见了面&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/07/20/%E5%8F%82%E5%8A%A0%E4%B8%80%E4%B</summary>
      
    
    
    
    <category term="程序设计" scheme="https://linweiyuan.github.io/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="Rust" scheme="https://linweiyuan.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>QEMU/KVM 盗贼之海虚拟机检测绕过</title>
    <link href="https://linweiyuan.github.io/2024/05/12/QEMU-KVM-%E7%9B%97%E8%B4%BC%E4%B9%8B%E6%B5%B7%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A3%80%E6%B5%8B%E7%BB%95%E8%BF%87.html"/>
    <id>https://linweiyuan.github.io/2024/05/12/QEMU-KVM-%E7%9B%97%E8%B4%BC%E4%B9%8B%E6%B5%B7%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A3%80%E6%B5%8B%E7%BB%95%E8%BF%87.html</id>
    <published>2024-05-12T10:08:28.000Z</published>
    <updated>2024-07-24T01:14:42.853Z</updated>
    
    <content type="html"><![CDATA[<p>之前有配置</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">features</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">kvm</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hidden</span> <span class="attr">state</span>=<span class="string">&quot;on&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">kvm</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">features</span>&gt;</span></span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">cpu</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">feature</span> <span class="attr">policy</span>=<span class="string">&quot;disable&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hypervisor&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">cpu</span>&gt;</span></span><br></pre></td></tr></table></figure><p>一切都是正常的</p><p>但是玩盗贼之海打开提示 “Cannot run under Virtual Machine.”</p><hr><p>上网查了下，加多一个配置可以解决，测试正常</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">os</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">smbios</span> <span class="attr">mode</span>=<span class="string">&quot;host&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">os</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;之前有配置&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;</summary>
      
    
    
    
    <category term="虚拟机" scheme="https://linweiyuan.github.io/categories/%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
    <category term="Windows" scheme="https://linweiyuan.github.io/tags/Windows/"/>
    
    <category term="KVM" scheme="https://linweiyuan.github.io/tags/KVM/"/>
    
    <category term="QEMU" scheme="https://linweiyuan.github.io/tags/QEMU/"/>
    
  </entry>
  
  <entry>
    <title>一次使用 AWS 服务的心路历程</title>
    <link href="https://linweiyuan.github.io/2024/05/02/%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-AWS-%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B.html"/>
    <id>https://linweiyuan.github.io/2024/05/02/%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-AWS-%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B.html</id>
    <published>2024-05-02T14:49:35.000Z</published>
    <updated>2024-07-24T01:14:42.857Z</updated>
    
    <content type="html"><![CDATA[<p>事情是这样的，几个月前有一个需求：用户在前端页面上输入查询条件调用 API 返回数据</p><p>很经典的简单 CRUD 对不对？我告诉你， 其实有点不同</p><p>因为这个查询除了其他可空条件外，有个必填的两个参数是开始时间和结束时间，而这个时间段，如果是当月（30 天内）的，API 要从数据库里面拿数据返回，而前面月份的则需要从 S3 的文件里拿，有个 Lambda 每天零点会定时执行任务，把数据库里超过 30 天的数据提取出来，生成 CSV 摆到 S3，然后删除数据库的数据</p><p>我们根据这个场景做过多轮压力测试，最终确定了每次从数据库里面拿 3000 是比较理想的，实现代码大概长这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cursor.execute(<span class="string">&#x27;select count xxx&#x27;</span>)</span><br><span class="line">row_count = cursor.rowcount</span><br><span class="line"><span class="keyword">if</span> row_count &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        fetch_rows = cursor.fetchmany(<span class="number">3000</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(fetch_rows) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> fetch_rows:</span><br><span class="line">                <span class="comment"># write csv</span></span><br></pre></td></tr></table></figure><p>这是第一版的代码</p><p>测试过程中发现可能未来的数据量会有点大，并且这个 Athena 收费也不便宜，如果不设置合适的索引，每次都需要查询很多没意义的数据再过滤，相当烧钱</p><p>于是经过对页面几个查询条件和数据库原来的结构进行分析后，设置了 Athena 的索引，这个索引在 Athena 里面叫 <code>partition key</code>，我们选用的是 Hive 风格</p><p>因此在 Bucket 上的 CSV 大概长这样：bucket&#x2F;year&#x3D;2024&#x2F;month&#x3D;01&#x2F;day&#x3D;01&#x2F;a&#x3D;xxx&#x2F;b&#x3D;xxx（这里的 a 和 b 是页面上一些查询条件）</p><p>代码也改为了先按照查询条件 <code>group by</code>，好生成 S3 目录结构，再按照具体的条件去查询对应的数据</p><p>铺垫了这么多，下面开始正文</p><h3 id="第一个坑：数据为什么查不出来？"><a href="#第一个坑：数据为什么查不出来？" class="headerlink" title="第一个坑：数据为什么查不出来？"></a>第一个坑：数据为什么查不出来？</h3><p>相信有过大数据开发经验的同学很快就能看到问题，数据是有了，但是 Athena 并不认识这些数据，还要 “告诉” Athena 从那里拿数据回来</p><p>有两个步骤可以选择，要么 <code>alter table add partition</code>，要么 <code>msck repair table</code>，因为按照我们的设计，这个结构理论上是不会有什么大的变化的，所以我们选择了第二种方式</p><p>执行完 repair 后，会看到输出了一堆 S3 路径，意思就是 Athena 认识这些数据了</p><h3 id="第二个坑：新的数据为什么查不出来？"><a href="#第二个坑：新的数据为什么查不出来？" class="headerlink" title="第二个坑：新的数据为什么查不出来？"></a>第二个坑：新的数据为什么查不出来？</h3><p>好了，每天定时任务都能成功把数据从数据库转移到 Bucket 中，但是为什么只能查到老的数据？</p><p>想象一下数据库新增数据的时候，索引是不是也会发生变化，原来这个 Athena 也是如此，不过，这个重建索引的过程需要人为介入</p><p>考虑到我们的数据是每天零点同步过去的，而要重建索引后，新的数据才能被查到，所以给这个 Lambda 在同步完数据后再跑个 repair 语句，解决问题</p><p>项目开始上线并稳定运行了一段时间</p><hr><p>上半部分结束，下半部分开始</p><p>新的需求过来了，和上面差不多，不过不是查数据显示，而是将查到的数据导出 CSV 然后下载下来</p><p>在这里需要先说明一下网络结构</p><p>有两个 AWS 账号，API 在账号 A，这个账号只有 EKS 服务，那些什么数据库、Lambda、Bucket、API Gateway 等等乱七八糟的全在另一个账号 B，API 通过 assume 账号 B 的 role 的方式来用账号 B 的服务</p><p>麻烦的方式不但在这里，还在明明在账号 B 创建好 role，赋予 S3 的增删改查和 Lambda 的执行权限，API 能够直接通过 assume role 来执行 Lambda 的情况下，API 还要通过私有 VPCE 来访问账号 B 的 API Gateway，API Gateway 再绑定 Lambda，这样蛋疼的方式来访问</p><p>问就是安全</p><p>人在江湖身不由己，也只好遵守他的游戏规则</p><p>在这个前提下，数据库那一部分很好处理，在 Athena 这里又出了幺蛾子</p><h3 id="第三个坑：数据太大-Lambda-超时"><a href="#第三个坑：数据太大-Lambda-超时" class="headerlink" title="第三个坑：数据太大 Lambda 超时"></a>第三个坑：数据太大 Lambda 超时</h3><p>用户点击下载 CSV，请求会这样走：API -&gt; AWS API Gateway -&gt; AWS Lambda -&gt; AWS Athena &#x2F; AWS RDS -&gt; AWS S3</p><p>而 Lambda 默认是同步执行的，如果数据量太大，那么如果用户点击下载后一直在转，显然不现实，于是我们将 Lambda 改成异步执行</p><p>Lambda 在 General 那里最大限额可以配置 15 分钟超时，10G 内存，10G 硬盘，而在 Async 相关的设置里，则可以设置为最长跑 6 个小时并且最多 2 次失败重试（自动）</p><p>既然写得这么明白，那么我们的数据也没这么大，不用跑几个小时，配置肯定是够用的，但是保险起见，先 sleep 个 16 分钟验证下？</p><p>不出意外的话，意外发生了</p><p>经过测试，虽然这个异步设置最长可以设置 6 小时，但是其实无论同步还是异步，Lambda 最长还是只能执行 15 分钟，这个 6 小时只是 Lambda 执行失败后会放在队列里的最长等待时间</p><p>就是说，就算用异步的方式执行耗时任务，在 15 分钟内没跑完，没关系，重试，还没跑完，也没关系，再重试，但在我们这个需求就不适用，因为是从头开始重试的，该拿不回来数据还是拿不回来</p><p>文档写得又乱，版本 V1、V2 又混着来，反正我是很蛋疼</p><p>15 分钟也行吧，Athena 查询东西本来就比较快，查询数据库都能 2-3 分钟跑完，Athena 不见得要超过这个时间吧？</p><p>现实又啪啪打脸</p><p>由于有之前上线生产环境的经验，那么我们从 Athena 里导出数据生成 CSV 下载，肯定还是沿用之前的老路：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">athena.start_query_execution()</span><br><span class="line">athena.get_query_execution()</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    query_execution_status == <span class="string">&#x27;SUCCEED&#x27;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">athena.get_query_results()</span><br></pre></td></tr></table></figure><p>问题来了，Athena 查询快是快，但是每次只能从中最多拿 1000 条数据回来，同时会返回一个叫 <code>NextToken</code> 这样的东西，后续请求需要带上它，才能获取后面的数据</p><p>那这就有问题了</p><p>经过测试，每次拿回来 1000 条数据大概花费 2-3 秒左右，那么 15 分钟极限最多拿不到 30W 条数据，一天的数据量远远超过这个</p><p>正当一筹莫展准备限定页面搜索条件，缩小总数据集，或者分拆成多个子任务再合并 CSV 时，猛然想到，其实 Athena 查询的时候往往需要指定一个结果输出路径，无论在 AWS Console 还是 boto3，并且是必填的，这个路径其实就是保存了本次查询的数据集和元数据</p><p>艹，怎么之前看漏了眼</p><p>结果就很美丽了，100W 数据查询才 10 秒，并且 CSV 都生成好了，只需移动下位置即可</p><h3 id="第四个坑：API-通过-API-Gateway-调用-Lambda-不是异步的"><a href="#第四个坑：API-通过-API-Gateway-调用-Lambda-不是异步的" class="headerlink" title="第四个坑：API 通过 API Gateway 调用 Lambda 不是异步的"></a>第四个坑：API 通过 API Gateway 调用 Lambda 不是异步的</h3><p>前面说过，不能让用户点击下载后在干等，所以需要异步执行这个 Lambda</p><p>好了，参考文档 <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-integration-async.html">Set up asynchronous invocation of the backend Lambda function</a> 进行设置，在 Lambda 里简单 <code>time.sleep(33)</code> 看看，因为 API 调用 API Gateway 超过 10 秒就要报错了，而 API Gateway 调用 Lambda 超过 30 秒也会报错，所以这样能试到两种情况</p><p>在没设置 <code>X-Amz-Invocation-Type</code> 请求头前，在 AWS Console 上面测试 API Gateway 调用 Lambda 是超时的，而设置了这个请求头后，正常了，但是 API 通过 API Gateway 来调用 Lambda，还是超时</p><p>这又是什么破玩意？</p><p>百思不得其解</p><p>Header 传得不对吗？</p><p>Lambda 没有设置好吗？</p><p>链接用错了吗？</p><p>有鬼</p><p>最后发现其实是忘记了重新部署 API Gateway</p><p>虽然是我们自己的锅，但是没有重新部署却在 AWS Console 上面测试也能通过，就很误导人</p><h3 id="第五个坑：无法利用自定义域名来生成-presignedUrl"><a href="#第五个坑：无法利用自定义域名来生成-presignedUrl" class="headerlink" title="第五个坑：无法利用自定义域名来生成 presignedUrl"></a>第五个坑：无法利用自定义域名来生成 presignedUrl</h3><p>下载 CSV 这个动作，考虑到 API 性能问题，没有将数据再经过 API 一遍流式返回前端徒增功耗，而是直接生成 presignedUrl，前端直接调用这个链接下载文件就完事了</p><p>这个链接，包含了 AWS 账号信息和 Bucket 信息，想将其隐藏掉，于是考虑到了利用自定义域名的方式来完成</p><p>最后配置好了路由，生成 presignedUrl，替换自定义域名，等等都完成后，通过新链接来访问文件，却说签名不匹配</p><p>也尝试过在代码里重写 endpointUrl 或者修改参与计算签名的 Host 字段，让它和我们的自定义域名一样，结果还是不行</p><p>查阅了相关文章，似乎也说，这其实就是 S3 的规范</p><p>感觉是没直接方法实现的，有的话，麻烦告知一下我</p><p>或者我们可以通过在 API 里映射的方式来实现？新增接口来专门处理这个，暴露 API 信息，但是可以有效隐藏掉 AWS 相关信息，这就是后话了</p><hr><h3 id="TBC"><a href="#TBC" class="headerlink" title="TBC"></a>TBC</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;事情是这样的，几个月前有一个需求：用户在前端页面上输入查询条件调用 API 返回数据&lt;/p&gt;
&lt;p&gt;很经典的简单 CRUD 对不对？我告诉你， 其实有点不同&lt;/p&gt;
&lt;p&gt;因为这个查询除了其他可空条件外，有个必填的两个参数是开始时间和结束时间，而这个时间段，如果是当月（30</summary>
      
    
    
    
    <category term="程序设计" scheme="https://linweiyuan.github.io/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="AWS" scheme="https://linweiyuan.github.io/tags/AWS/"/>
    
    <category term="Athena" scheme="https://linweiyuan.github.io/tags/Athena/"/>
    
    <category term="Lambda" scheme="https://linweiyuan.github.io/tags/Lambda/"/>
    
    <category term="API Gateway" scheme="https://linweiyuan.github.io/tags/API-Gateway/"/>
    
  </entry>
  
  <entry>
    <title>Stable Code Instruct 3B 本地部署</title>
    <link href="https://linweiyuan.github.io/2024/03/31/Stable-Code-Instruct-3B-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.html"/>
    <id>https://linweiyuan.github.io/2024/03/31/Stable-Code-Instruct-3B-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.html</id>
    <published>2024-03-31T12:56:36.000Z</published>
    <updated>2024-07-24T01:14:42.853Z</updated>
    
    <content type="html"><![CDATA[<p>官方简介：<a href="https://stability.ai/news/introducing-stable-code-instruct-3b">https://stability.ai/news/introducing-stable-code-instruct-3b</a></p><p>总的来说，和 <a href="https://linweiyuan.github.io/2023/12/07/ChatGLM2-6B-INT4%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.html">ChatGLM2-6B-INT4 本地部署</a> 差不多，需要安装 <code>transformers</code> 和 <code>torch</code></p><p>流式输出例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer, TextStreamer</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;stabilityai/stable-code-instruct-3b&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;stabilityai/stable-code-instruct-3b&quot;</span>, torch_dtype=torch.bfloat16, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model = model.cuda()</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful and polite assistant&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;show me a demo code to connect to aws lambda using golang&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=<span class="literal">True</span>, tokenize=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer([prompt], return_tensors=<span class="string">&quot;pt&quot;</span>).to(model.device)</span><br><span class="line"></span><br><span class="line">tokens = model.generate(</span><br><span class="line">    **inputs,</span><br><span class="line">    max_new_tokens=<span class="number">1024</span>,</span><br><span class="line">    temperature=<span class="number">0.5</span>,</span><br><span class="line">    top_p=<span class="number">0.95</span>,</span><br><span class="line">    top_k=<span class="number">100</span>,</span><br><span class="line">    do_sample=<span class="literal">True</span>,</span><br><span class="line">    use_cache=<span class="literal">True</span>,</span><br><span class="line">    pad_token_id=tokenizer.eos_token_id,</span><br><span class="line">    streamer=TextStreamer(tokenizer=tokenizer, skip_prompt=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">output = tokenizer.batch_decode(tokens[:, inputs.input_ids.shape[-<span class="number">1</span>]:], skip_special_tokens=<span class="literal">False</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2024/03/31/Stable-Code-Instruct-3B-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/test.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;官方简介：&lt;a href=&quot;https://stability.ai/news/introducing-stable-code-instruct-3b&quot;&gt;https://stability.ai/news/introducing-stable-code-instruct-3</summary>
      
    
    
    
    <category term="AI" scheme="https://linweiyuan.github.io/categories/AI/"/>
    
    
    <category term="LLM" scheme="https://linweiyuan.github.io/tags/LLM/"/>
    
    <category term="Stability AI" scheme="https://linweiyuan.github.io/tags/Stability-AI/"/>
    
  </entry>
  
  <entry>
    <title>Chrome 新版 UI 回滚</title>
    <link href="https://linweiyuan.github.io/2023/12/15/Chrome%E6%96%B0%E7%89%88UI%E5%9B%9E%E6%BB%9A.html"/>
    <id>https://linweiyuan.github.io/2023/12/15/Chrome%E6%96%B0%E7%89%88UI%E5%9B%9E%E6%BB%9A.html</id>
    <published>2023-12-15T14:02:40.000Z</published>
    <updated>2024-07-24T01:14:42.845Z</updated>
    
    <content type="html"><![CDATA[<p>新版界面是真的用不上，<code>i3wm</code> 鼠标移到最上面经常获取不到标签页的焦点，字体和书签间隔还莫名其妙的大</p><p>如何回滚？</p><p>打开<code>chrome://flags</code>，将 <code>Chrome WebUI Refresh 2023</code> 设为 <code>Disabled</code></p><p>世界又美好了</p><p>有感觉这个特性一定会在不久的将来被删掉</p><h1 id="2024-03-20"><a href="#2024-03-20" class="headerlink" title="2024-03-20"></a>2024-03-20</h1><p>日常 <code>yay</code> 更新了下，参数还失效了，不过多了新参数</p><p><code>Customize Chrome Side Panel</code> 继续改为 <code>Disabled</code></p><p>当前版本：<code>Version 123.0.6312.58 (Official Build) (64-bit)</code></p><p>还这样乱搞，我要转 <code>Firefox</code> 了</p><h1 id="2024-05-17"><a href="#2024-05-17" class="headerlink" title="2024-05-17"></a>2024-05-17</h1><p>今天日常滚下系统，发现有更新，于是升到 125，然后不出所料，打开浏览器发现这个脑残的设计又回来了，上面的 <code>flags</code> 已经不见<br>无奈只能从源头入手</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /usr/share/applications/google-chrome.desktop</span><br></pre></td></tr></table></figure><p>改成 <code>Exec=/usr/bin/google-chrome-stable %U --disable-features=CustomizeChromeSidePanel</code></p><p>今天下了个火狐，再容忍它一下</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;新版界面是真的用不上，&lt;code&gt;i3wm&lt;/code&gt; 鼠标移到最上面经常获取不到标签页的焦点，字体和书签间隔还莫名其妙的大&lt;/p&gt;
&lt;p&gt;如何回滚？&lt;/p&gt;
&lt;p&gt;打开&lt;code&gt;chrome://flags&lt;/code&gt;，将 &lt;code&gt;Chrome WebUI Re</summary>
      
    
    
    
    <category term="浏览器" scheme="https://linweiyuan.github.io/categories/%E6%B5%8F%E8%A7%88%E5%99%A8/"/>
    
    
    <category term="Chrome" scheme="https://linweiyuan.github.io/tags/Chrome/"/>
    
  </entry>
  
  <entry>
    <title>Caddy + WebSocket + V2Ray</title>
    <link href="https://linweiyuan.github.io/2023/12/09/Caddy-WebSocket-V2Ray.html"/>
    <id>https://linweiyuan.github.io/2023/12/09/Caddy-WebSocket-V2Ray.html</id>
    <published>2023-12-09T06:59:43.000Z</published>
    <updated>2024-07-24T01:14:42.845Z</updated>
    
    <content type="html"><![CDATA[<p>基于 Arch Linux</p><p>可选：<a href="https://linweiyuan.github.io/2017/08/22/Arch-Linux%E5%BC%80%E5%90%AFBBR-%E9%87%8D%E5%90%AF%E4%B8%8D%E5%A4%B1%E6%95%88.html">BBR</a></p><hr><ol><li>安装软件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S v2ray caddy</span><br></pre></td></tr></table></figure><ol start="2"><li>配置 V2Ray</li></ol><p>编辑配置文件 <code>/etc/v2ray/vpoint_vmess_freedom.json</code>，在 <code>inbounds</code> 里面加一段配置，<code>path</code> 对应的值自定义，供后续使用，这里用 <code>/ws</code>，<code>id</code> 可随便生成一个 <code>UUID</code>，比如通过 <code>cat /proc/sys/kernel/random/uuid</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&quot;streamSettings&quot;: &#123;</span><br><span class="line">    &quot;network&quot;: &quot;ws&quot;,</span><br><span class="line">    &quot;wsSettings&quot;: &#123;</span><br><span class="line">        &quot;path&quot;: &quot;/ws&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外重要的一点，<code>alterId</code> 改成 <code>0</code>，原因自己查</p><p>开启服务：<code>sudo systemctl enable --now v2ray@vpoint_vmess_freedom</code></p><ol start="3"><li>配置 Caddy</li></ol><p>新增配置文件 <code>/etc/caddy/conf.d/xxx</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[域名] &#123;</span><br><span class="line">    reverse_proxy [比如上面的 /ws] :[上面配置的端口] &#123;</span><br><span class="line">        header_up -Origin</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>开启服务：<code>sudo systemctl enable --now caddy</code></p><ol start="4"><li><p>（可选）启动 CDN，隐藏源站 IP（试过 Cloudflare，速度惨不忍睹）</p></li><li><p><code>v2rayA</code> 客户端配置</p></li></ol><table><thead><tr><th align="center">Key</th><th align="center">Value</th></tr></thead><tbody><tr><td align="center">Host</td><td align="center">域名</td></tr><tr><td align="center">Port</td><td align="center">443</td></tr><tr><td align="center">ID</td><td align="center">UUID（上面的）</td></tr><tr><td align="center">AlterID</td><td align="center">0</td></tr><tr><td align="center">Security</td><td align="center">Auto</td></tr><tr><td align="center">TLS</td><td align="center">tls</td></tr><tr><td align="center">SNI</td><td align="center">空</td></tr><tr><td align="center">uTLS fingerprint</td><td align="center">空</td></tr><tr><td align="center">AllowInsecure</td><td align="center">否</td></tr><tr><td align="center">Network</td><td align="center">WebSocket</td></tr><tr><td align="center">Host</td><td align="center">域名</td></tr><tr><td align="center">Alpn</td><td align="center">空</td></tr><tr><td align="center">Path</td><td align="center">上面的 WebSocket 路径</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;基于 Arch Linux&lt;/p&gt;
&lt;p&gt;可选：&lt;a href=&quot;https://linweiyuan.github.io/2017/08/22/Arch-Linux%E5%BC%80%E5%90%AFBBR-%E9%87%8D%E5%90%AF%E4%B8%8D%E5%A</summary>
      
    
    
    
    <category term="操作系统" scheme="https://linweiyuan.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Caddy" scheme="https://linweiyuan.github.io/tags/Caddy/"/>
    
    <category term="WebSocket" scheme="https://linweiyuan.github.io/tags/WebSocket/"/>
    
    <category term="V2Ray" scheme="https://linweiyuan.github.io/tags/V2Ray/"/>
    
  </entry>
  
  <entry>
    <title>ChatGLM2-6B-INT4 本地部署</title>
    <link href="https://linweiyuan.github.io/2023/12/07/ChatGLM2-6B-INT4%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.html"/>
    <id>https://linweiyuan.github.io/2023/12/07/ChatGLM2-6B-INT4%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.html</id>
    <published>2023-12-07T17:33:24.000Z</published>
    <updated>2024-07-24T01:14:42.845Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下供下次玩耍参考，当前环境：</p><p>Arch Linux：6.6.4-arch1-1<br>Python：3.11.6<br>Nvidia：545.29.06<br>CUDA：12.3<br>GPU：NVIDIA GeForce RTX 3060 Ti<br>ChatGLM: chatglm2-6b-int4</p><hr><ol><li>Arch Linux 安装 NVIDIA 系包</li></ol><p><a href="https://wiki.archlinux.org/title/NVIDIA">Wiki</a> 说现在有个新包 <code>nvidia-open</code>，我试过直接用原来的 <code>nvidia</code> 系统会莫名其妙卡，换成新包一切正常</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nvidia-open</span><br></pre></td></tr></table></figure><p>如果源码方式运行，上面的就够了，容器运行需要安装多一个，<code>AUR</code> 或者直接 <code>archlinuxcn</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nvidia-container-toolkit</span><br></pre></td></tr></table></figure><p>由于显卡满足不了 <code>chatglm2-6b</code>，会爆显存 <code>orch.cuda.OutOfMemoryError: CUDA out of memory.</code>，因此只能用 <code>chatglm2-6b-int4</code> 的版本，这里用源码的方式，方便改动后直接运行</p><p>如果是首次安装 <code>nvidia-open</code> 包，需重启系统生效</p><ol start="2"><li><p>克隆官方仓库：<code>gh repo clone THUDM/ChatGLM2-6B</code>，这个 <code>gh</code> 需要额外安装 <code>github-cli</code>，用 <code>git clone</code> 也可以</p></li><li><p>进去 <code>ChatGLM2-6B</code> 文件夹，创建一个虚拟环境 <code>python -m venv .venv</code>，执行 <code>source .venv/bin/activate</code> 激活（取消激活 <code>deactivate</code>），又或者利用 <code>oh-my-zsh</code> 的插件功能 <code>virtualenvwrapper</code>，进入项目目录后自动激活（需要安装 <code>python-virtualenvwrapper</code> 包）</p></li><li><p>下载依赖 <code>pip install -r requirements.txt</code></p></li><li><p>修改代码 <code>web_demo.py</code>、<code>web_demo2.py</code>、或 <code>cli_demo.py</code>，将 <code>THUDM/chatglm2-6b</code> 改为 <code>THUDM/chatglm2-6b-int4</code>，接着执行即可</p></li></ol><ul><li><code>python web_demo.py</code></li><li><code>streamlit run web_demo2.py</code></li><li><code>python cli_demo.py</code></li></ul><p>模型会自动下载模型到 <code>~/.cache/huggingface/hub</code> （或者改为本地已经下载好的路径，可以到 <a href="https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/?p=/&mode=list">清华大学云盘</a> 下载，这个我没试过，<code>web_demo.py</code> 我自己测试网页会报错，其他两个正常）</p><p>如果遇到报错 <code>RuntimeError: Library cudart is not initialized</code>，则需要安装 <code>cuda</code> 包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S cuda</span><br></pre></td></tr></table></figure><p>相同环境用起来，速度 <code>chatglm2-6b-int4</code> 比 <code>chatglm-6b-int4</code> 快一点，其他的没仔细测试</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;记录一下供下次玩耍参考，当前环境：&lt;/p&gt;
&lt;p&gt;Arch Linux：6.6.4-arch1-1&lt;br&gt;Python：3.11.6&lt;br&gt;Nvidia：545.29.06&lt;br&gt;CUDA：12.3&lt;br&gt;GPU：NVIDIA GeForce RTX 3060 Ti&lt;br&gt;</summary>
      
    
    
    
    <category term="AI" scheme="https://linweiyuan.github.io/categories/AI/"/>
    
    
    <category term="LLM" scheme="https://linweiyuan.github.io/tags/LLM/"/>
    
    <category term="ChatGLM" scheme="https://linweiyuan.github.io/tags/ChatGLM/"/>
    
  </entry>
  
  <entry>
    <title>QEMU下 Win10 硬盘动态扩容</title>
    <link href="https://linweiyuan.github.io/2023/12/07/QEMU%E4%B8%8BWin10%E7%A1%AC%E7%9B%98%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9.html"/>
    <id>https://linweiyuan.github.io/2023/12/07/QEMU%E4%B8%8BWin10%E7%A1%AC%E7%9B%98%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9.html</id>
    <published>2023-12-07T12:01:42.000Z</published>
    <updated>2024-07-24T01:14:42.853Z</updated>
    
    <content type="html"><![CDATA[<p>在 KVM + QEMU 的场景下，可以进去 <code>/var/lib/libvirt/images</code> 目录，然后通过通过 <code>sudo qemu-img resize win10.qcow2 +10G</code> 去修改硬盘大小</p><p>因为我们一开始并不知道硬盘需要多大空间，并且如果要配合 <code>sdelete</code> 这种来使用的话，太大的硬盘耗时相对更多</p><p>但是，默认情况下，通过 <code>resize</code> 命令去扩容后，在 Windows 系统 <code>磁盘管理</code> 那里的空间是不能直接合并到 C 盘的，要新建一个 D 盘，空间不连续导致不方便的同时，还对强迫症患者不友好</p><p>这个时候只需要把恢复分区删掉就可以合并过去 C 盘了，一般来说用处不大，况且我们可以直接备份 <code>win10.qcow2</code></p><hr><ol><li>管理员打开 CMD，执行 <code>diskpart</code></li><li><code>list disk</code> 列出所有硬盘</li><li><code>select disk 0</code> 通常 C 盘是第 0 个</li><li><code>list partition</code> 列出所有分区</li><li><code>select partition 4</code> 通常恢复分区是第 4 个</li><li><code>delete partition override</code> 提示 <code>DiskPart 成功地删除了所选分区。</code> 则大功告成</li><li>打开硬盘管理直接右键合并新扩容的空间即可</li></ol><hr><p>一个例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">Microsoft DiskPart 版本 10.0.19041.3636</span><br><span class="line"></span><br><span class="line">Copyright (C) Microsoft Corporation.</span><br><span class="line">在计算机上: KVM</span><br><span class="line"></span><br><span class="line">DISKPART&gt; list disk</span><br><span class="line"></span><br><span class="line">  磁盘 ###  状态           大小     可用     Dyn  Gpt</span><br><span class="line">  --------  -------------  -------  -------  ---  ---</span><br><span class="line">  磁盘 0    联机              350 GB   300 GB        *</span><br><span class="line">  磁盘 1    联机              465 GB  1024 KB</span><br><span class="line"></span><br><span class="line">DISKPART&gt; select disk 0</span><br><span class="line"></span><br><span class="line">磁盘 0 现在是所选磁盘。</span><br><span class="line"></span><br><span class="line">DISKPART&gt; list partition</span><br><span class="line"></span><br><span class="line">  分区 ###       类型              大小     偏移量</span><br><span class="line">  -------------  ----------------  -------  -------</span><br><span class="line">  分区      1    系统                 100 MB  1024 KB</span><br><span class="line">  分区      2    保留                  16 MB   101 MB</span><br><span class="line">  分区      3    主要                  49 GB   117 MB</span><br><span class="line">  分区      4    恢复                 583 MB    49 GB</span><br><span class="line"></span><br><span class="line">DISKPART&gt; select partition 4</span><br><span class="line"></span><br><span class="line">分区 4 现在是所选分区。</span><br><span class="line"></span><br><span class="line">DISKPART&gt; delete partition override</span><br><span class="line"></span><br><span class="line">DiskPart 成功地删除了所选分区。</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 KVM + QEMU 的场景下，可以进去 &lt;code&gt;/var/lib/libvirt/images&lt;/code&gt; 目录，然后通过通过 &lt;code&gt;sudo qemu-img resize win10.qcow2 +10G&lt;/code&gt; 去修改硬盘大小&lt;/p&gt;
&lt;p&gt;因</summary>
      
    
    
    
    <category term="虚拟机" scheme="https://linweiyuan.github.io/categories/%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
    <category term="Windows" scheme="https://linweiyuan.github.io/tags/Windows/"/>
    
    <category term="KVM" scheme="https://linweiyuan.github.io/tags/KVM/"/>
    
    <category term="QEMU" scheme="https://linweiyuan.github.io/tags/QEMU/"/>
    
  </entry>
  
  <entry>
    <title>删除 Win10 的网络x</title>
    <link href="https://linweiyuan.github.io/2023/12/06/%E5%88%A0%E9%99%A4Win10%E7%9A%84%E7%BD%91%E7%BB%9Cx.html"/>
    <id>https://linweiyuan.github.io/2023/12/06/%E5%88%A0%E9%99%A4Win10%E7%9A%84%E7%BD%91%E7%BB%9Cx.html</id>
    <published>2023-12-06T08:38:54.000Z</published>
    <updated>2024-07-24T01:14:42.857Z</updated>
    
    <content type="html"><![CDATA[<p>在前面显卡直通文章介绍过通过 KVM + QEMU 直通显卡使用 Windows 系统的场景，当一个系统安装好后，其实可以将原始硬盘 <code>win10.qcow2</code> 备份下来（类似 Ghost），这样当重装 Arch Linux 的时候，不用重新配置 Windows 系统，直接修改 virt-manager 里面 Windows 10 系统的 xml 文件即可（只需替换成新 UUID）</p><p>但是，每次使用这块硬盘后，在系统启动进去的时候，会提示新的“网络2”、“网络3”连接，虽然不影响使用，但是强迫症忍不了</p><p>如何解决？</p><p>注册表大法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\NetworkList\Profiles</span><br><span class="line">HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\NetworkList\Signatures\Unmanaged</span><br></pre></td></tr></table></figure><p>将上面两个项下面的子项全部删除后重启系统，即可重新提示一个新的“网络”</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在前面显卡直通文章介绍过通过 KVM + QEMU 直通显卡使用 Windows 系统的场景，当一个系统安装好后，其实可以将原始硬盘 &lt;code&gt;win10.qcow2&lt;/code&gt; 备份下来（类似 Ghost），这样当重装 Arch Linux 的时候，不用重新配置 Wi</summary>
      
    
    
    
    <category term="操作系统" scheme="https://linweiyuan.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Windows" scheme="https://linweiyuan.github.io/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>QEMU 多 USB 设备直通</title>
    <link href="https://linweiyuan.github.io/2023/12/03/QEMU%E5%A4%9AUSB%E8%AE%BE%E5%A4%87%E7%9B%B4%E9%80%9A.html"/>
    <id>https://linweiyuan.github.io/2023/12/03/QEMU%E5%A4%9AUSB%E8%AE%BE%E5%A4%87%E7%9B%B4%E9%80%9A.html</id>
    <published>2023-12-03T05:19:47.000Z</published>
    <updated>2024-07-24T01:14:42.853Z</updated>
    
    <content type="html"><![CDATA[<p>比如我有两个相同的 U 盘要直通过去，如果通过 virt-manager 直接操作，会提示这个错误 <code>Unable to add device: XML error: Hostdev already exists in the domain configuration</code></p><p>经过排查，发现默认情况下，两个 <code>vendor</code> 和 <code>product</code> 相同的配置不能同时出现</p><hr><p>解决办法如下（Arch Linux）：<br>首先需要确保系统安装有 <code>usbutils</code> 这个包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S usbutils</span><br></pre></td></tr></table></figure><p>接着通过命令 <code>lsusb</code> 查询到 <code>Bus</code> 和 <code>Device</code></p><p>比如原来的配置如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hostdev</span> <span class="attr">mode</span>=<span class="string">&quot;subsystem&quot;</span> <span class="attr">type</span>=<span class="string">&quot;usb&quot;</span> <span class="attr">managed</span>=<span class="string">&quot;yes&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">vendor</span> <span class="attr">id</span>=<span class="string">&quot;0x1234&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">product</span> <span class="attr">id</span>=<span class="string">&quot;0xabcd&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">address</span> <span class="attr">type</span>=<span class="string">&quot;usb&quot;</span> <span class="attr">bus</span>=<span class="string">&quot;0&quot;</span> <span class="attr">port</span>=<span class="string">&quot;1&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">hostdev</span>&gt;</span></span><br></pre></td></tr></table></figure><p>修改后的配置如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hostdev</span> <span class="attr">mode</span>=<span class="string">&quot;subsystem&quot;</span> <span class="attr">type</span>=<span class="string">&quot;usb&quot;</span> <span class="attr">managed</span>=<span class="string">&quot;yes&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">vendor</span> <span class="attr">id</span>=<span class="string">&quot;0x1234&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">product</span> <span class="attr">id</span>=<span class="string">&quot;0xabcd&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">address</span> <span class="attr">bus</span>=<span class="string">&#x27;1&#x27;</span> <span class="attr">device</span>=<span class="string">&#x27;1&#x27;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">address</span> <span class="attr">type</span>=<span class="string">&quot;usb&quot;</span> <span class="attr">bus</span>=<span class="string">&quot;0&quot;</span> <span class="attr">port</span>=<span class="string">&quot;1&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">hostdev</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样就可以正常添加</p><hr><p>当然还有曲线救国的方案：直通一个 USB HUB</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;比如我有两个相同的 U 盘要直通过去，如果通过 virt-manager 直接操作，会提示这个错误 &lt;code&gt;Unable to add device: XML error: Hostdev already exists in the domain configurati</summary>
      
    
    
    
    <category term="虚拟机" scheme="https://linweiyuan.github.io/categories/%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
    <category term="KVM" scheme="https://linweiyuan.github.io/tags/KVM/"/>
    
    <category term="QEMU" scheme="https://linweiyuan.github.io/tags/QEMU/"/>
    
  </entry>
  
  <entry>
    <title>Arch Linux 多显卡切换配置</title>
    <link href="https://linweiyuan.github.io/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE.html"/>
    <id>https://linweiyuan.github.io/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE.html</id>
    <published>2023-09-23T12:05:10.000Z</published>
    <updated>2024-07-24T01:14:42.845Z</updated>
    
    <content type="html"><![CDATA[<p>书接上回 <a href="https://linweiyuan.github.io/2022/11/25/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A-PCI-passthrough-via-OVMF.html">虚拟机显卡直通 (PCI passthrough via OVMF)</a></p><hr><h1 id="系统准备"><a href="#系统准备" class="headerlink" title="系统准备"></a>系统准备</h1><p>现在的台式机 CPU，动不动就不带核显，但那个是插着电源线的，不用考虑如何省电</p><p>而现在的笔记本，动不动就是核显加独显，并且 BIOS 里不一定带独显开关。这就造成了一种困扰：我现在没有玩游戏或其他用显卡的需求，只是写写代码，然而刚好在外面没插电，这样独显就还一直是通着电的状态，电池本来能用 5 小时，现在 3 小时就没电了。所以，有没有一种方法，可以在 BIOS 不支持独显开关的情况下，按需关掉或者开启独显？</p><p>答案是有，并且有很多种方案。但是这里按照我的个人喜好，只介绍 <a href="https://github.com/bayasdev/envycontrol">EnvyControl</a> 这一种（其他的我试过，水土不服）</p><hr><p>Arch Linux 安装完成后，默认是用的开源驱动 <code>nouveau</code>，网上说官方的闭源驱动性能更好，那么首先就给系统装上闭源驱动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nvidia</span><br></pre></td></tr></table></figure><p>然后你可以配置一些钩子，让系统自动重新生成初始化内存镜像，或者简单粗暴地手动生成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkinitcpio -p linux</span><br></pre></td></tr></table></figure><p>上面的命令是基于当前最新 Linux 内核的，如果你用的是其他内核或者自定义内核，那么则自己按需修改</p><p>然后重启系统，显卡驱动就算安装完成了</p><p>接着就是重头戏，安装 <code>envycontrol</code>，但是这个包只在 <code>AUR</code> 里，所以需要通过 <code>yay</code> 或者其他工具进行安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -S envycontrol</span><br></pre></td></tr></table></figure><hr><h1 id="核显-独显"><a href="#核显-独显" class="headerlink" title="核显 + 独显"></a>核显 + 独显</h1><p>默认情况下，当前模式是核显 + 独显（至少我自己的笔记本是这样），或者可以通过下面命令切换（每次切换都要重启系统，这个很好理解，因为有时要拉黑一些驱动和修改 <code>udev</code> 规则）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo envycontrol -s hybrid</span><br></pre></td></tr></table></figure><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/envycontrol_hybrid.png"></p><p>如何测试当前显卡使用情况？可以查看 <code>glxinfo</code> 的输出信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">glxinfo | grep <span class="string">&quot;OpenGL renderer&quot;</span></span><br></pre></td></tr></table></figure><p>比如我的笔记本输出如下内容</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/glxinfo_intel.png"></p><hr><p>既然说核显 + 独显都是通电的，怎么确认呢？</p><p>多种方法，比如 <code>lspci</code>，不过这个输出多少会让人眼花缭乱，所以这里用人看的一目了然的方法 <code>neofetch</code></p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/neofetch_intel_nvidia.png"></p><p>这里很明显看到核显和独显都是在线的</p><p>但是用 <code>nvidia-smi</code> 会发现，是没有任何进程在用独显的</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/nvidia_smi_no_processes.png"></p><p>但是也可以看到功耗是有的，虽然不多，但是细水长流</p><hr><p>那么既然独显在线，又没人用，还用着电，浪费就浪费在这里了</p><p>所以在核显 + 独显（也叫 <code>hybrid</code>）模式，默认是使用核显的，但是独显也通电，当你想用的时候就可以通过一些另外的方式用，比如 <code>prime-run</code>，安装也很简单</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nvidia-prime</span><br></pre></td></tr></table></figure><p>这个时候在需要使用独显的程序或者命令前加 <code>prime-run</code>，就可以用到独显，比如上面的改成这样</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prime-run glxinfo | grep <span class="string">&quot;OpenGL renderer string&quot;</span></span><br></pre></td></tr></table></figure><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/prime_run_glxinfo.png"></p><p>这样就能按需使用独显</p><h1 id="独显"><a href="#独显" class="headerlink" title="独显"></a>独显</h1><p>比如当前插着电，或者就是想要更高性能的表现，则可以切换为独显模式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo envycontrol -s nvidia</span><br></pre></td></tr></table></figure><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/envycontrol_nvidia.png"></p><p>这个时候直接执行 <code>glxinfo</code> （带 <code>prime-run</code> 或者不带都一样），则会提示目前正在使用的是独显</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/glxinfo_nvidia.png"></p><p>并且会看到也有进程使用独显了（如果这个时候使用 <code>neofetch</code>，核显也是会有的，因为它有其他工作要做，比如设置屏幕亮度之类的）</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/nvidia_smi_processes.png"></p><p>没意外的话，所有新进程都用独显</p><h1 id="核显"><a href="#核显" class="headerlink" title="核显"></a>核显</h1><p>这个就是文章一开头的场景，切换命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo envycontrol -s integrated</span><br></pre></td></tr></table></figure><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/envycontrol_integrated.png"></p><p>这个时候执行 <code>neofetch</code> 则看不到独显了，也就是不通电了</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/neofetch_nvidia.png"></p><p>那么执行 <code>glxinfo</code> 当然显示核显了</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/glxinfo_integrated.png"></p><p>如果执行独显相关的 <code>prime-run</code> 或者 <code>nvidia-smi</code> 则肯定报错了</p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/prime_run_error.png"></p><p><img src="/2023/09/23/Arch-Linux-%E5%A4%9A%E6%98%BE%E5%8D%A1%E5%88%87%E6%8D%A2%E9%85%8D%E7%BD%AE/nvidia_smi_error.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;书接上回 &lt;a href=&quot;https://linweiyuan.github.io/2022/11/25/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A-PCI-passthrough-via</summary>
      
    
    
    
    <category term="操作系统" scheme="https://linweiyuan.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Arch Linux" scheme="https://linweiyuan.github.io/tags/Arch-Linux/"/>
    
    <category term="Nvidia" scheme="https://linweiyuan.github.io/tags/Nvidia/"/>
    
  </entry>
  
  <entry>
    <title>如何生成 GPT-4 arkose_token</title>
    <link href="https://linweiyuan.github.io/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token.html"/>
    <id>https://linweiyuan.github.io/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token.html</id>
    <published>2023-06-24T15:10:24.000Z</published>
    <updated>2024-07-24T01:14:42.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="本篇文章已过期，仅供思路参考"><a href="#本篇文章已过期，仅供思路参考" class="headerlink" title="本篇文章已过期，仅供思路参考"></a>本篇文章已过期，仅供思路参考</h1><h1 id="20230626-早上"><a href="#20230626-早上" class="headerlink" title="20230626 早上"></a>20230626 早上</h1><p>以下逆向 JS 内容已过期，参考：<a href="https://github.com/acheong08/ChatGPT/issues/1431#issuecomment-1606145567">https://github.com/acheong08/ChatGPT/issues/1431#issuecomment-1606145567</a></p><p>有另一种简单的方法生成 <code>arkose_token</code>：<a href="https://github.com/linweiyuan/chatgpt-arkose-token-api">chatgpt-arkose-token-api</a></p><h1 id="20230626-下午"><a href="#20230626-下午" class="headerlink" title="20230626 下午"></a>20230626 下午</h1><p>当天，似乎上面的方法又失效了，所以还是先用回下面的方法</p><h1 id="20230626-夜里-20230627"><a href="#20230626-夜里-20230627" class="headerlink" title="20230626 夜里 - 20230627"></a>20230626 夜里 - 20230627</h1><p><code>arkose_token</code> 突然不检测了，但是还是先传着，保持和官网一样</p><h1 id="2023-06-28"><a href="#2023-06-28" class="headerlink" title="2023-06-28"></a>2023-06-28</h1><p>又开始检测了</p><h1 id="2023-07-08"><a href="#2023-07-08" class="headerlink" title="2023-07-08"></a>2023-07-08</h1><p><a href="https://github.com/linweiyuan/chatgpt-arkose-token-api">chatgpt-arkose-token-api</a> 复活，主要是借鉴了 <a href="https://github.com/xyhelper/xyhelper-arkose">xyhelper&#x2F;xyhelper-arkose</a></p><p>把 <code>html</code> 页面放在服务器上运行，不行，会弹验证码</p><p>但是单独起个服务跑 <code>html</code> 页面，又可以，莫名其妙</p><p>（我自己测试，如果服务器上开启了 <code>IPv6</code>，会拿不到 <code>token</code>，原因未知）</p><p>服务健康程度监控页面：<a href="https://stats.churchless.tech/">Health Status</a></p><h1 id="2023-07-27"><a href="#2023-07-27" class="headerlink" title="2023-07-27"></a>2023-07-27</h1><p>方法已失效，不折腾了</p><h1 id="2023-09-24"><a href="#2023-09-24" class="headerlink" title="2023-09-24"></a>2023-09-24</h1><p>更新视频，通过抓 har 包获取合法 token（这个方法已经存在很久了，但是最近比较忙，也基本弃坑了没用 GPT，所以鸽到现在更新）</p><h1 id="2023-10-02"><a href="#2023-10-02" class="headerlink" title="2023-10-02"></a>2023-10-02</h1><p>原来本来就有更加方便的方法，之前没有注意，现在更新，无需额外再跑一个 token 服务</p><hr><h1 id="GPT-4-403"><a href="#GPT-4-403" class="headerlink" title="GPT-4 403"></a>GPT-4 403</h1><p>GPT-4 对 <code>arkose_token</code> 的校验在最近几天里每天都改变很多次，有时早上提交代码，下午就失效，或者晚上提交，第二天失效</p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/403.png"></p><p>通过不断的试错，把所有缺失的参数全部补上，但是最后还是 403 了</p><p>于是，打算从源头出发，学习一下 JS 的逆向（本人 JS 相对新手，但是曾经也写过）</p><h1 id="arkose-token-从何来"><a href="#arkose-token-从何来" class="headerlink" title="arkose_token 从何来"></a>arkose_token 从何来</h1><p>接口：<code>https://tcr9i.chat.openai.com/fc/gt2/public_key/35536E1E-65B4-4D96-9D97-6ADB7EFF8147</code></p><p>FormData:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bda: ct + iv + s 的 base64 编码</span><br><span class="line">public_key: 35536E1E-65B4-4D96-9D97-6ADB7EFF8147</span><br><span class="line">site: https://chat.openai.com</span><br><span class="line">userbrowser: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36</span><br><span class="line">capi_version: 1.5.2</span><br><span class="line">capi_mode: lightbox</span><br><span class="line">style_theme: default</span><br><span class="line">rnd: 随机数，小数点后有时 16 位，有时 17 位</span><br></pre></td></tr></table></figure><p>其他参数都是写死，并且之前不传也可以，最近必须要传，并且还要传对，不然 403</p><p>重点就是在 bda 参数里，里面的内容是加密的</p><h1 id="bda"><a href="#bda" class="headerlink" title="bda"></a>bda</h1><p>通过 F12，一步一步跟，发现了一些蛛丝马迹，最后调用的是这个方法来生成 bda 参数：<code>ALFCCJS.encrypt(bx, bv + bw)</code></p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/encrypt.png"></p><p>于是反推，如何生成 <code>bx</code>、<code>bv</code> 和 <code>bw</code></p><h1 id="bx"><a href="#bx" class="headerlink" title="bx"></a>bx</h1><p><code>bx</code> 依赖 <code>b5</code> 和 <code>bg</code></p><p><code>b5</code> 是一个数组，里面的东西大部分都是写死的，除了一个时间戳</p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/b5.png"></p><p><code>bg</code> 写死的，本次测试不传也正常（未来可能有校验）</p><p>将 <code>b5</code> 数组转成字符串，就得到了 <code>bx</code></p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/bx.png"></p><h1 id="bv"><a href="#bv" class="headerlink" title="bv"></a>bv</h1><p><code>bv</code> 没什么好说的，就是当前浏览器 <code>UA</code> 写死</p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/bv.png"></p><h1 id="bw"><a href="#bw" class="headerlink" title="bw"></a>bw</h1><p><code>bw</code> 不复杂，当前时间戳然后计算一下</p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/bw.png"></p><h1 id="200"><a href="#200" class="headerlink" title="200"></a>200</h1><p>最后执行加密方法，就能生成加密 <code>bda</code></p><p>如果提示 <code>ALFCCJS is not defined</code>，执行下面 JS 将其初始化 </p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> script = <span class="variable language_">document</span>.<span class="title function_">createElement</span>(<span class="string">&quot;script&quot;</span>);</span><br><span class="line">script.<span class="property">type</span> = <span class="string">&quot;text/javascript&quot;</span>;</span><br><span class="line">script.<span class="property">src</span> = <span class="string">&quot;https://tcr9i.chat.openai.com/cdn/fc/js/6af2c0d87b9879cbf3365be1a208293f84d37b1e/standard/funcaptcha_api.js&quot;</span>;</span><br><span class="line"><span class="variable language_">document</span>.<span class="property">head</span>.<span class="title function_">appendChild</span>(script);</span><br></pre></td></tr></table></figure><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/bda.png"></p><p>再设置到参数里调用接口就能拿到 <code>arkose_token</code></p><p>GPT-4 就 200 了</p><p><img src="/2023/06/24/%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90-GPT-4-arkose-token/200.png"></p><h1 id="视频（共三个）"><a href="#视频（共三个）" class="headerlink" title="视频（共三个）"></a>视频（共三个）</h1><p>一开始看错了 <code>bv</code> 成 <code>by</code>，但是字幕烧录进去了，懒得改了，其实是 <code>bx</code>, <code>bv</code>, <code>bw</code></p><div>  <video-js id="videojs-id-889a0306-81dd-4aaf-a7d4-7ed82b6e77a1"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/how-to-generate-gpt-4-arkose-token/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid889a030681dd4aafa7d47ed82b6e77a1 = videojs('videojs-id-889a0306-81dd-4aaf-a7d4-7ed82b6e77a1', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> <hr><div>  <video-js id="videojs-id-9be6fb17-241a-4c9c-9f48-dd4ba923044e"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/how-to-generate-gpt-4-arkose-token-new/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid9be6fb17241a4c9c9f48dd4ba923044e = videojs('videojs-id-9be6fb17-241a-4c9c-9f48-dd4ba923044e', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> <hr><div>  <video-js id="videojs-id-9de6cb6a-500a-45bc-ae97-7f0abc3880ac"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/how-to-generate-gpt-4-arkose-token-latest/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid9de6cb6a500a45bcae977f0abc3880ac = videojs('videojs-id-9de6cb6a-500a-45bc-ae97-7f0abc3880ac', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;本篇文章已过期，仅供思路参考&quot;&gt;&lt;a href=&quot;#本篇文章已过期，仅供思路参考&quot; class=&quot;headerlink&quot; title=&quot;本篇文章已过期，仅供思路参考&quot;&gt;&lt;/a&gt;本篇文章已过期，仅供思路参考&lt;/h1&gt;&lt;h1 id=&quot;20230626-早上&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="AI" scheme="https://linweiyuan.github.io/categories/AI/"/>
    
    <category term="ChatGPT" scheme="https://linweiyuan.github.io/categories/AI/ChatGPT/"/>
    
    
    <category term="ChatGPT" scheme="https://linweiyuan.github.io/tags/ChatGPT/"/>
    
    <category term="GPT-4" scheme="https://linweiyuan.github.io/tags/GPT-4/"/>
    
  </entry>
  
  <entry>
    <title>利用 HTTP Client 来调试 go-chatgpt-api</title>
    <link href="https://linweiyuan.github.io/2023/06/18/%E5%88%A9%E7%94%A8-HTTP-Client-%E6%9D%A5%E8%B0%83%E8%AF%95-go-chatgpt-api.html"/>
    <id>https://linweiyuan.github.io/2023/06/18/%E5%88%A9%E7%94%A8-HTTP-Client-%E6%9D%A5%E8%B0%83%E8%AF%95-go-chatgpt-api.html</id>
    <published>2023-06-18T12:31:41.000Z</published>
    <updated>2024-07-24T01:14:42.857Z</updated>
    
    <content type="html"><![CDATA[<p>接口调试</p><div>  <video-js id="videojs-id-2d54a4c4-765b-4c6e-8dc2-39c0c514cfc4"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/http-client-debug-go-chatgpt-api/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid2d54a4c4765b4c6e8dc239c0c514cfc4 = videojs('videojs-id-2d54a4c4-765b-4c6e-8dc2-39c0c514cfc4', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;接口调试&lt;/p&gt;
&lt;div&gt;
  &lt;video-js id=&quot;videojs-id-2d54a4c4-765b-4c6e-8dc2-39c0c514cfc4&quot; 
    class=&quot;vjs-default-skin vjs-16-9&quot; 
    controls 
   </summary>
      
    
    
    
    <category term="AI" scheme="https://linweiyuan.github.io/categories/AI/"/>
    
    <category term="ChatGPT" scheme="https://linweiyuan.github.io/categories/AI/ChatGPT/"/>
    
    
    <category term="ChatGPT" scheme="https://linweiyuan.github.io/tags/ChatGPT/"/>
    
    <category term="HTTP Client" scheme="https://linweiyuan.github.io/tags/HTTP-Client/"/>
    
  </entry>
  
  <entry>
    <title>Cloudflare 实用功能</title>
    <link href="https://linweiyuan.github.io/2023/05/31/Cloudflare-%E5%AE%9E%E7%94%A8%E5%8A%9F%E8%83%BD.html"/>
    <id>https://linweiyuan.github.io/2023/05/31/Cloudflare-%E5%AE%9E%E7%94%A8%E5%8A%9F%E8%83%BD.html</id>
    <published>2023-05-31T14:56:13.000Z</published>
    <updated>2024-07-24T01:14:42.845Z</updated>
    
    <content type="html"><![CDATA[<p>域名、CDN、DNS 解析、日志，这些老生常谈的就不多说了</p><p>免费版本也同时支持一些 DDoS 防护和 WAF，通过简单的设置即可挡掉绝大多数恶意请求和机器人，还支持限流配置，非常良心</p><p>Workers 和 Pages 这些还没用过</p><p>这里简单说一下 <code>Zero Trust</code>，目前用得比较多</p><hr><h1 id="Zero-Trust"><a href="#Zero-Trust" class="headerlink" title="Zero Trust"></a>Zero Trust</h1><p>什么是 Zero Trust？官方解释：<a href="https://www.cloudflare.com/zh-cn/learning/security/glossary/what-is-zero-trust/">https://www.cloudflare.com/zh-cn/learning/security/glossary/what-is-zero-trust/</a></p><p>利用普通人理解的大白话来说，就是一个 <code>VPN</code> 服务</p><h2 id="WARP"><a href="#WARP" class="headerlink" title="WARP"></a>WARP</h2><p>Cloudflare 提供了一个叫做 <code>WARP</code> 的程序，普通用户每次注册就会提供 1G 免费流量，而如果利用一些其他软件刷流量，则可达到无限流量（这个我没有细心研究，目前还没试过刷流量）</p><p>而更提供了一种名为 <code>Team</code> 的服务，利用它的 <code>teams-enroll-token</code> 也可实现无限流量，它会提供一个登录页面，并且可以配置指定邮箱才能收到邮件，里面有验证链接，通过后即可直接打开 WARP 客户端</p><p>举个实际应用案例：ChatGPT 不久前封禁了一大堆 VPS 的访问，一旦发出请求，全是 <code>Sorry, you have been blocked</code> 之类，这个时候如果利用这个服务，那么如果请求通过这个代理连出去，就能正常访问 ChatGPT 的接口，VPS 得以继续发光发热</p><p>为此我做了一个镜像配合服务一起使用：<a href="https://hub.docker.com/r/linweiyuan/chatgpt-proxy-server-warp">linweiyuan&#x2F;chatgpt-proxy-server-warp</a></p><p>但是，经过我测试，如果利用 <code>Team</code> 账号，虽然说是无限流量，但是经常超过一定流量就连不上，所以我设置成 <code>Free</code> 账号自动检测流量使用情况，超过 1G 了就会自动重新注册</p><p>（注意默认情况下开启 <code>Team</code> 账号后，是不允许设置 <code>proxy-mode</code> 的，具体忘记是不是会直接断开链接还是什么报错，反正用布料，需要进入 <code>Settings -&gt; WARP Client -&gt; Device settings</code> 里面设置）</p><p>当时这个注册的操作我钻了好久牛角尖，怎么每次使用都是注册，后来释然了，没有关系，能用就行，除非你有刷过无限流量的账号，就可以自己设置进去，但是太麻烦了</p><h2 id="Tunnels"><a href="#Tunnels" class="headerlink" title="Tunnels"></a>Tunnels</h2><p>还有一个就是 <code>Tunnels</code>，这个是 Cloudflare 提供的内网穿透，在 <code>Access</code> 菜单里</p><p>和 <code>frp</code> 不同的是，不需要一台服务器（<code>P2P</code> 没用过），直接跑一个程序即可，Cloudflare 自动完成域名解析，完后访问域名就可以看到内网服务了，延迟因人而异，尝试下还是不错的</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;域名、CDN、DNS 解析、日志，这些老生常谈的就不多说了&lt;/p&gt;
&lt;p&gt;免费版本也同时支持一些 DDoS 防护和 WAF，通过简单的设置即可挡掉绝大多数恶意请求和机器人，还支持限流配置，非常良心&lt;/p&gt;
&lt;p&gt;Workers 和 Pages 这些还没用过&lt;/p&gt;
&lt;p&gt;这</summary>
      
    
    
    
    <category term="Cloudflare" scheme="https://linweiyuan.github.io/categories/Cloudflare/"/>
    
    
    <category term="Cloudflare" scheme="https://linweiyuan.github.io/tags/Cloudflare/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT in Next.js</title>
    <link href="https://linweiyuan.github.io/2023/05/20/ChatGPT-in-Next-js.html"/>
    <id>https://linweiyuan.github.io/2023/05/20/ChatGPT-in-Next-js.html</id>
    <published>2023-05-20T12:28:28.000Z</published>
    <updated>2024-07-24T01:14:42.845Z</updated>
    
    <content type="html"><![CDATA[<p>近几天看到一个视频：<a href="https://www.youtube.com/watch?v=PGPGcKBpAk8">Real-Time Messenger Clone: Next.js 13, React, Tailwind, Prisma, MongoDB, NextAuth, Pusher (2023)</a>，看到里面的样式不错，于是进行了学习、模仿、借鉴、参考、抄袭，打算弄个小项目练练手（前端新手强烈建议看看视频，真的学到很多东西，这个油管主写代码不墨迹，该解释时会解释，其他时间也没废话）</p><p>因为我也是个新手，不会写 <code>CSS</code>，于是样式基本照搬视频教程，然后把里面提到的聊天和推送功能进行了一个魔改，实现了一个比较简陋的第三方 <code>ChatGPT</code> 客户端：<a href="https://github.com/linweiyuan/next-chatgpt">Next-ChatGPT</a>，能基本实现对话，并且可以高亮代码和流式输出（现学现改，很多 <code>Bug</code>，过段时间学多点前端再优化下，只能说能用）</p><p>在这个过程中巩固了下 <code>React</code> 的知识，并且学习了 <code>Next.js</code>、<code>Tailwind CSS</code> 等好用的工具，对 <code>SSR</code> 也有更加深入的了解，感叹前端开发之精妙，明白为什么说凡是能用 <code>JS</code> 写的最终都会用 <code>JS</code></p><hr><p>但是后端开发思维先入为主根深蒂固，开发过程中多次钻牛角尖，非常痛苦</p><p>比如这个官方文档里说，在服务端使用 <code>hook</code>：<a href="https://next-auth.js.org/tutorials/securing-pages-and-api-routes#server-side">Securing pages and API routes</a>，还有文档缺少 <code>TS</code> 的例子，也比较更新不及时</p><p>（不得不说，还是写 API 香，但是往往写前端才能称得上是一个作品，能获得更多关注）</p><hr><h2 id="魔改成果"><a href="#魔改成果" class="headerlink" title="魔改成果"></a>魔改成果</h2><div>  <video-js id="videojs-id-a82cbe33-b212-444b-b212-4c37b350d5e2"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/next-chatgpt/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsida82cbe33b212444bb2124c37b350d5e2 = videojs('videojs-id-a82cbe33-b212-444b-b212-4c37b350d5e2', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;近几天看到一个视频：&lt;a href=&quot;https://www.youtube.com/watch?v=PGPGcKBpAk8&quot;&gt;Real-Time Messenger Clone: Next.js 13, React, Tailwind, Prisma, MongoDB, </summary>
      
    
    
    
    <category term="AI" scheme="https://linweiyuan.github.io/categories/AI/"/>
    
    <category term="ChatGPT" scheme="https://linweiyuan.github.io/categories/AI/ChatGPT/"/>
    
    
    <category term="ChatGPT" scheme="https://linweiyuan.github.io/tags/ChatGPT/"/>
    
    <category term="Next.js" scheme="https://linweiyuan.github.io/tags/Next-js/"/>
    
    <category term="Tailwind CSS" scheme="https://linweiyuan.github.io/tags/Tailwind-CSS/"/>
    
  </entry>
  
  <entry>
    <title>LMMS-One Summer&#39;s Day</title>
    <link href="https://linweiyuan.github.io/2023/05/12/LMMS-One-Summer-s-Day.html"/>
    <id>https://linweiyuan.github.io/2023/05/12/LMMS-One-Summer-s-Day.html</id>
    <published>2023-05-12T17:34:52.000Z</published>
    <updated>2024-07-24T01:14:42.849Z</updated>
    
    <content type="html"><![CDATA[<div>  <video-js id="videojs-id-2a7bc11f-0841-4a04-b4f7-e1d5c74dad43"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/lmms-one-summer-s-day/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid2a7bc11f08414a04b4f7e1d5c74dad43 = videojs('videojs-id-2a7bc11f-0841-4a04-b4f7-e1d5c74dad43', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;div&gt;
  &lt;video-js id=&quot;videojs-id-2a7bc11f-0841-4a04-b4f7-e1d5c74dad43&quot; 
    class=&quot;vjs-default-skin vjs-16-9&quot; 
    controls 
    preload=&quot;au</summary>
      
    
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/categories/LMMS/"/>
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/tags/LMMS/"/>
    
    <category term="千与千寻" scheme="https://linweiyuan.github.io/tags/%E5%8D%83%E4%B8%8E%E5%8D%83%E5%AF%BB/"/>
    
    <category term="One Summer&#39;s Day" scheme="https://linweiyuan.github.io/tags/One-Summer-s-Day/"/>
    
  </entry>
  
  <entry>
    <title>LMMS-Always With Me</title>
    <link href="https://linweiyuan.github.io/2023/05/12/LMMS-Always-With-Me.html"/>
    <id>https://linweiyuan.github.io/2023/05/12/LMMS-Always-With-Me.html</id>
    <published>2023-05-12T05:40:18.000Z</published>
    <updated>2024-07-24T01:14:42.849Z</updated>
    
    <content type="html"><![CDATA[<div>  <video-js id="videojs-id-5ab60855-1fa3-4f0d-ba5d-9c7cdaf2f5c3"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/lmms-always-with-me/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid5ab608551fa34f0dba5d9c7cdaf2f5c3 = videojs('videojs-id-5ab60855-1fa3-4f0d-ba5d-9c7cdaf2f5c3', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;div&gt;
  &lt;video-js id=&quot;videojs-id-5ab60855-1fa3-4f0d-ba5d-9c7cdaf2f5c3&quot; 
    class=&quot;vjs-default-skin vjs-16-9&quot; 
    controls 
    preload=&quot;au</summary>
      
    
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/categories/LMMS/"/>
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/tags/LMMS/"/>
    
    <category term="Always With Me" scheme="https://linweiyuan.github.io/tags/Always-With-Me/"/>
    
    <category term="千与千寻" scheme="https://linweiyuan.github.io/tags/%E5%8D%83%E4%B8%8E%E5%8D%83%E5%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>LMMS-一百万个可能</title>
    <link href="https://linweiyuan.github.io/2023/05/10/LMMS-%E4%B8%80%E7%99%BE%E4%B8%87%E4%B8%AA%E5%8F%AF%E8%83%BD.html"/>
    <id>https://linweiyuan.github.io/2023/05/10/LMMS-%E4%B8%80%E7%99%BE%E4%B8%87%E4%B8%AA%E5%8F%AF%E8%83%BD.html</id>
    <published>2023-05-10T17:42:20.000Z</published>
    <updated>2024-07-24T01:14:42.849Z</updated>
    
    <content type="html"><![CDATA[<div>  <video-js id="videojs-id-f67e75ea-498b-4eba-899a-b655f0ed34b8"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/lmms-a-million-possibilities/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsidf67e75ea498b4eba899ab655f0ed34b8 = videojs('videojs-id-f67e75ea-498b-4eba-899a-b655f0ed34b8', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;div&gt;
  &lt;video-js id=&quot;videojs-id-f67e75ea-498b-4eba-899a-b655f0ed34b8&quot; 
    class=&quot;vjs-default-skin vjs-16-9&quot; 
    controls 
    preload=&quot;au</summary>
      
    
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/categories/LMMS/"/>
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/tags/LMMS/"/>
    
    <category term="一百万个可能" scheme="https://linweiyuan.github.io/tags/%E4%B8%80%E7%99%BE%E4%B8%87%E4%B8%AA%E5%8F%AF%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>LMMS-孤勇者</title>
    <link href="https://linweiyuan.github.io/2023/05/08/LMMS-%E5%AD%A4%E5%8B%87%E8%80%85.html"/>
    <id>https://linweiyuan.github.io/2023/05/08/LMMS-%E5%AD%A4%E5%8B%87%E8%80%85.html</id>
    <published>2023-05-08T16:41:25.000Z</published>
    <updated>2024-07-24T01:14:42.849Z</updated>
    
    <content type="html"><![CDATA[<div>  <video-js id="videojs-id-493ed30c-8f03-4610-83e6-f916e1b9a659"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/lmms-lonely-warrior/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid493ed30c8f03461083e6f916e1b9a659 = videojs('videojs-id-493ed30c-8f03-4610-83e6-f916e1b9a659', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;div&gt;
  &lt;video-js id=&quot;videojs-id-493ed30c-8f03-4610-83e6-f916e1b9a659&quot; 
    class=&quot;vjs-default-skin vjs-16-9&quot; 
    controls 
    preload=&quot;au</summary>
      
    
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/categories/LMMS/"/>
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/tags/LMMS/"/>
    
    <category term="孤勇者" scheme="https://linweiyuan.github.io/tags/%E5%AD%A4%E5%8B%87%E8%80%85/"/>
    
  </entry>
  
  <entry>
    <title>LMMS-夜的钢琴曲五</title>
    <link href="https://linweiyuan.github.io/2023/05/06/LMMS-%E5%A4%9C%E7%9A%84%E9%92%A2%E7%90%B4%E6%9B%B2%E4%BA%94.html"/>
    <id>https://linweiyuan.github.io/2023/05/06/LMMS-%E5%A4%9C%E7%9A%84%E9%92%A2%E7%90%B4%E6%9B%B2%E4%BA%94.html</id>
    <published>2023-05-06T16:10:14.000Z</published>
    <updated>2024-07-24T01:14:42.849Z</updated>
    
    <content type="html"><![CDATA[<div>  <video-js id="videojs-id-3a2397e1-f8ef-4358-9483-04e740374531"     class="vjs-default-skin vjs-16-9"     controls     preload="auto"     width="100%"     height="350px">    <source src="/video/lmms-melody-of-the-night-5/index.m3u8" type="application&#x2F;x-mpegURL">  </video-js>      <script>    const videojsid3a2397e1f8ef4358948304e740374531 = videojs('videojs-id-3a2397e1-f8ef-4358-9483-04e740374531', {      html5: {        hls: {          overrideNative: true        }      }    });  </script>  </div> ]]></content>
    
    
      
      
    <summary type="html">&lt;div&gt;
  &lt;video-js id=&quot;videojs-id-3a2397e1-f8ef-4358-9483-04e740374531&quot; 
    class=&quot;vjs-default-skin vjs-16-9&quot; 
    controls 
    preload=&quot;au</summary>
      
    
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/categories/LMMS/"/>
    
    
    <category term="LMMS" scheme="https://linweiyuan.github.io/tags/LMMS/"/>
    
    <category term="夜的钢琴曲" scheme="https://linweiyuan.github.io/tags/%E5%A4%9C%E7%9A%84%E9%92%A2%E7%90%B4%E6%9B%B2/"/>
    
  </entry>
  
</feed>
